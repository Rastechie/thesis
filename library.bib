Automatically generated by Mendeley Desktop 1.18
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Reich2015,
author = {Reich, Justin and Tingley, Dustin and Luis, Jetson Leder and Roberts, Margaret E and Stewart, Brandon M},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/74da37dab4829cb9fb81272682126a164be6.pdf:pdf},
keywords = {assisted,computer,massive open online courses,text analysis,topic modelling},
pages = {156--184},
title = {{Computer-Assisted Reading and Discovery for Student-Generated Text in Massive Open Online Courses 1 OVERVIEW}},
volume = {2},
year = {2015}
}
@article{Roberts2017,
abstract = {This vignette demonstrates how to use the Structural Topic Model stm R package. The Structural Topic Model allows researchers to flexibly estimate a topic model that includes document-level meta-data. Estimation is accomplished through a fast variational approximation. The stm package provides many useful features, including rich ways to explore topics, estimate uncertainty, and visualize quantities of interest.},
archivePrefix = {arXiv},
arxivId = {1709.04553},
author = {{Margaret E. Roberts, Brandon M. Stewart}, Dustin Tingley},
doi = {10.18637/jss.v000.i00},
eprint = {1709.04553},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/stmVignette.pdf:pdf},
keywords = {LDA,R,lda,r,spectral,stm,structural topic model,text analysis},
mendeley-tags = {lda,spectral,stm},
number = {Ii},
title = {{stm: R Package for Structural Topic Models}},
url = {http://arxiv.org/abs/1709.04553},
volume = {VV},
year = {2017}
}
@article{Rosen-Zvi2004,
abstract = {We introduce the author-topic model, a gen- erative model for documents that extends La- tent Dirichlet Allocation (LDA; Blei, Ng, {\&} Jordan, 2003) to include authorship informa- tion. Each author is associated with a multi- nomial distribution over topics and each topic is associated with a multinomial distribution over words. A document with multiple au- thors is modeled as a distribution over topics that is a mixture of the distributions associ- ated with the authors. We apply the model to a collection of 1,700 NIPS conference pa- pers and 160,000 CiteSeer abstracts. Exact inference is intractable for these datasets and we use Gibbs sampling to estimate the topic and author distributions. We compare the performance with two other generative mod- els for documents, which are special cases of the author-topic model: LDA (a topic model) and a simple author model in which each au- thor is associated with a distribution over words rather than a distribution over top- ics. We show topics recovered by the author- topic model, and demonstrate applications to computing similarity between authors and entropy of author output.},
archivePrefix = {arXiv},
arxivId = {1207.4169},
author = {Rosen-Zvi, M. and Griffiths, T. and Steyvers, M. and Smyth, P.},
doi = {10.1016/j.nima.2010.11.062},
eprint = {1207.4169},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/The Author-Topic Model for Authors and Documents.pdf:pdf},
isbn = {0-9749039-0-6},
issn = {01689002},
journal = {Proceedings of the 20th conference on Uncertainty in artificial intelligence},
keywords = {Author topic model},
pages = {487--494},
title = {{The author-topic model for authors and documents}},
url = {http://portal.acm.org/citation.cfm?id=1036902},
year = {2004}
}
@article{Feinerer2008,
abstract = {During the last decade text mining has become a widely used discipline utilizing sta- tistical and machine learning methods. We present the tm package which provides a framework for text mining applications within R. We give a survey on text mining facili- ties in R and explain how typical application tasks can be carried out using our framework. We present techniques for count-based analysismethods, text clustering, text classification and string kernels.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Feinerer, Ingo and Hornik, Kurt and Meyer, David},
doi = {citeulike-article-id:2842334},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Text Mining Infrastructure in R.pdf:pdf},
isbn = {1548-7660},
issn = {15487660},
journal = {Journal Of Statistical Software},
keywords = {count based evaluation,r,string,text classification,text clustering,text mining},
number = {5},
pages = {1--54},
pmid = {25246403},
title = {{Text Mining Infrastructure in R}},
url = {http://www.jstatsoft.org/v25/i05},
volume = {25},
year = {2008}
}
@article{Eisenstein2013,
abstract = {The rise of social media has brought compu-tational linguistics in ever-closer contact with bad language: text that defies our expecta-tions about vocabulary, spelling, and syntax. This paper surveys the landscape of bad lan-guage, and offers a critical review of the NLP community's response, which has largely fol-lowed two paths: normalization and domain adaptation. Each approach is evaluated in the context of theoretical and empirical work on computer-mediated communication. In addi-tion, the paper presents a quantitative analy-sis of the lexical diversity of social media text, and its relationship to other corpora.},
author = {Eisenstein, Jacob},
doi = {10.1016/j.febslet.2009.03.055},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/N13-1037.pdf:pdf},
isbn = {9781937284473},
issn = {0003-9993},
journal = {NAACL HLT 2013 - 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Main Conference},
number = {June},
pages = {359--369},
pmid = {9915371},
title = {{What to do about bad language on the internet}},
url = {http://www.scopus.com/inward/record.url?partnerID=HzOxMe3b{\&}scp=84926139009{\&}origin=inward{\%}0Apapers3://publication/uuid/04BB701C-1B3E-469E-818D-B08D0FF20AD9},
year = {2013}
}
@article{Wagner2010,
author = {Wagner, Claudia},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/mlss09uk{\_}blei{\_}tm.pdf:pdf},
title = {{Topic Models}},
year = {2010}
}
@article{Henderson2014,
abstract = {User interactions in social data tell us a great deal about the real world, and these insights are not limited to any particular segments of time. By under- standing the time-dependent behavior of groups of social media users, we can identify and even predict important real-world trends. What sort of real-world activities, events, and trends might be re ected in social data? And what properties of those events might we want to know? Suppose that an in uential nancial analyst Tweets a strong opinion about a particular stock and that Tweet goes viral. Or suppose a large number of customers use Twitter to complain about a brand's new product. In both cases, good rst questions are: when did the event happen, or when did the trend start? As a follow-up, we can also ask: how signi cant is the change? How large is the increase or decrease? More importantly, how large is this change relative to typical changes on Twitter? The quanti cation not only allows an analyst to distinguish the atypical from the typical, but it also allows them to compare one atypical event to another. Are there characteristics of atypical events that allow them to be separated into groups that can then be assigned real-world meaning (e.g. seasonal trends, holiday events)? If so, do these assignments point toward a particular choice of quantitative model for the event? If the identi cation of an atypical period of time can be quanti ed, can it be automated? And can it be used to predict future behavior? After reading this paper, you will be well on your way to building a system for discovering, measuring, comparing and discussing changes in time series data that arise from online social interactions.},
author = {Henderson, Scott and Kolb, Jeff and Lehman, Brian and Montague, Joshua},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Trend Detection in Social Data.pdf:pdf},
journal = {Working paper},
keywords = {Time Series},
mendeley-tags = {Time Series},
title = {{Trend detection in social data}},
year = {2014}
}
@article{Lucas2015,
abstract = {Recent advances in research tools for the systematic analysis of textual data are enabling exciting new research throughout the social sciences. For comparative politics, scholars who are often interested in non-English and possibly multilingual textual datasets, these advances may be difficult to access. This article discusses practical issues that arise in the processing, management, translation, and analysis of textual data with a particular focus on how procedures differ across languages. These procedures are combined in two applied examples of automated text analysis using the recently introduced Structural Topic Model. We also show how the model can be used to analyze data that have been translated into a single language via machine translation tools. All the methods we describe here are implemented in open-source software packages available from the authors.},
author = {Lucas, Christopher and Nielsen, Richard A. and Roberts, Margaret E. and Stewart, Brandon M. and Storer, Alex and Tingley, Dustin},
doi = {10.1093/pan/mpu019},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/comparativepoliticstext.pdf:pdf},
isbn = {1047-1987$\backslash$r1476-4989},
issn = {14764989},
journal = {Political Analysis},
number = {2},
pages = {254--277},
title = {{Computer-assisted text analysis for comparative politics}},
volume = {23},
year = {2015}
}
@article{Sokolova2016,
abstract = {The tremendous growth of social media content on the Internet has inspired the development of the text analytics to understand and solve real-life problems. Leveraging statistical topic modelling helps researchers and practitioners in better comprehension of textual content as well as provides useful information for further analysis. Statistical topic modelling becomes especially important when we work with large volumes of dynamic text, e.g., Facebook or Twitter datasets. In this study, we summarize the message content of four data sets of Twitter messages relating to challenging social events in Kenya. We use Latent Dirichlet Allocation (LDA) topic modelling to analyze the content. Our study uses two evaluation measures, Normalized Mutual Information (NMI) and topic coherence analysis, to select the best LDA models. The obtained LDA results show that the tool can be effectively used to extract discussion topics and summarize them for further manual analysis},
archivePrefix = {arXiv},
arxivId = {1608.02519},
author = {Sokolova, Marina and Huang, Kanyi and Matwin, Stan and Ramisch, Joshua and Sazonova, Vera and Black, Renee and Orwa, Chris and Ochieng, Sidney and Sambuli, Nanjira},
eprint = {1608.02519},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Topic Modelling and Event Identification from.pdf:pdf},
journal = {arXiv preprint arXiv:1608.02519},
keywords = {Introduction,Normalized Mutual Information results,unimportant},
mendeley-tags = {Introduction},
pages = {17},
title = {{Topic Modelling and Event Identification from Twitter Textual Data}},
url = {http://arxiv.org/abs/1608.02519},
year = {2016}
}
@article{Davi2018,
author = {Davi, Angelique and Haughton, Dominique and Nasr, Nada and Shah, Gaurav and Skaletsky, Maria and Spack, Ruth and Davi, Ang and Haughton, Dominique and Nasr, Nada and Shah, Gaurav and Skaletsky, Maria and Spack, Ruth},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/SAS text Mining and Wordstat.pdf:pdf},
number = {1},
pages = {89--103},
title = {{A Review of Two Text-Mining Packages : SAS TextMining and WordStat}},
volume = {59},
year = {2018}
}
@article{Hofmann1999,
abstract = {Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain-specific synonymy as well as with polysemous words. In con trast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with different dimensionalities has proven to be advantageous.},
archivePrefix = {arXiv},
arxivId = {2073829},
author = {Hofmann, Thomas},
doi = {10.1145/312624.312649},
eprint = {2073829},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Probabilistic Latent Semantic Indexing.pdf:pdf},
isbn = {1581130961},
issn = {15206882},
journal = {Sigir},
keywords = {pLSI},
mendeley-tags = {pLSI},
pages = {50--57},
pmid = {18989936},
title = {{Probabilistic latent semantic indexing}},
url = {http://portal.acm.org/citation.cfm?doid=312624.312649},
year = {1999}
}
@article{Ye2016,
abstract = {Social media activity has become an important component of daily life for many people. Messages from Twitter (US) and Weibo (China) have shown their potential as important data sources for detecting and analyzing infectious diseases. Such emerging and dynamic new data sources allow us to predict how infectious diseases develop and evolve both spatially and temporally. We report the dynamics of dengue fever in China using messages from Weibo. We first extract and construct a list of keywords related to dengue fever in order to analyze how frequently these words appear in Weibo messages based on the Latent Dirichlet Allocation (LDA). Spatial analysis is then applied to detect how dengue fever cases cluster spatially and spread over time.},
author = {Ye, Xinyue and Li, Shengwen and Yang, Xining and Qin, Chenglin},
doi = {10.3390/ijgi5090156},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Use of social media for disease detection.pdf:pdf},
isbn = {22209964},
issn = {2220-9964},
journal = {ISPRS International Journal of Geo-Information},
number = {9},
pages = {156},
title = {{Use of Social Media for the Detection and Analysis of Infectious Diseases in China}},
url = {http://www.mdpi.com/2220-9964/5/9/156},
volume = {5},
year = {2016}
}
@article{Weng2010,
abstract = {This paper focuses on the problem of identifying influential users of micro-blogging services. Twitter, one of the most notable micro-blogging services, employs a social-networking model called " following " , in which each user can choose who she wants to " follow " to receive tweets from without requir-ing the latter to give permission first. In a dataset prepared for this study, it is observed that (1) 72.4{\%} of the users in Twitter follow more than 80{\%} of their followers, and (2) 80.5{\%} of the users have 80{\%} of users they are following follow them back. Our study reveals that the presence of " reciprocity " can be explained by phenomenon of homophily [14]. Based on this finding, TwitterRank, an extension of PageRank algorithm, is proposed to measure the influence of users in Twitter. TwitterRank measures the influence taking both the topical similarity between users and the link struc-ture into account. Experimental results show that Twit-terRank outperforms the one Twitter currently uses and other related algorithms, including the original PageRank and Topic-sensitive PageRank.},
author = {Weng, Jianshu and {Peng LIM}, Ee and Jiang, Jing and Lim, Ee-Peng and He, Qi},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Twitterrank- Finding Topic-Sensitive Influential Twitterers.pdf:pdf},
isbn = {9781605588896},
keywords = {Design,Experimentation Keywords Twitter,H31 [Information Storage and Retrieval],PageRank,influential,retrieval model},
pages = {261--270},
title = {{Twitterrank: Finding Topic-Sensitive Influential Twitterers}},
url = {http://ink.library.smu.edu.sg/sis{\_}research},
year = {2010}
}
@article{Response2012,
abstract = {Metadata are associated to most of the information we produce in our daily interactions and communication in the digital world. Yet, surprisingly, metadata are often still catergorized as non-sensitive. Indeed, in the past, researchers and practitioners have mainly focused on the problem of the identification of a user from the content of a message. In this paper, we use Twitter as a case study to quantify the uniqueness of the association between metadata and user identity and to understand the effectiveness of potential obfuscation strategies. More specifically, we analyze atomic fields in the metadata and systematically combine them in an effort to classify new tweets as belonging to an account using different machine learning algorithms of increasing complexity. We demonstrate that through the application of a supervised learning algorithm, we are able to identify any user in a group of 10,000 with approximately 96.7{\%} accuracy. Moreover, if we broaden the scope of our search and consider the 10 most likely candidates we increase the accuracy of the model to 99.22{\%}. We also found that data obfuscation is hard and ineffective for this type of data: even after perturbing 60{\%} of the training data, it is still possible to classify users with an accuracy higher than 95{\%}. These results have strong implications in terms of the design of metadata obfuscation strategies, for example for data set release, not only for Twitter, but, more generally, for most social media platforms.},
archivePrefix = {arXiv},
arxivId = {1803.10133},
author = {Response, Child Labour},
eprint = {1803.10133},
file = {:D$\backslash$:/MSc DA/Project docs/Identification and Obfuscation of Social Media Users.pdf:pdf},
isbn = {9781577357988},
number = {July 2011},
title = {{Pakistan Earthquake : Child Labour Response}},
year = {2012}
}
@article{Benhardus2013,
abstract = {As social media continue to grow, the zeitgeist of society is increasingly found not in the headlines of traditional media institutions, but in the activity of ordinary individuals. The identification of trending topics utilises social media (such as Twitter) to provide an overview of the topics and issues that are currently popular within the online community. In this paper, we outline methodologies of detecting and identifying trending topics from streaming data. Data from Twitter's streaming API was collected and put into documents of equal duration using data collection procedures that allow for analysis over multiple timespans, including those not currently associated with Twitter-identified trending topics. Term frequency-inverse document frequency analysis and relative normalised term frequency analysis were performed on the documents to identify the trending topics. Relative normalised term frequency analysis identified unigrams, bigrams, and trigrams as trending topics, while term frequency-inverse document frequency analysis identified unigrams as trending topics. Application of these methodologies to streaming data resulted in F-measures ranging from 0.1468 to 0.7508.},
author = {Benhardus, James and Kalita, Jugal},
doi = {10.1504/IJWBC.2013.051298},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Streaming trend detection in Twitter.pdf:pdf},
issn = {1477-8394},
journal = {International Journal of Web Based Communities},
keywords = {1,122,139,2013,9,Introduction,Relative normalised term frequency,TF-IDF,and kalita,benhardus,follows,human language processing,int,j,microblogs,no,pp,problem defination,reference to this paper,related work,should be made as,streaming trend detection in,tf-idf,trend detection,twitter,vol,web based communities},
mendeley-tags = {Introduction,Relative normalised term frequency,TF-IDF,problem defination,related work},
number = {1},
pages = {122},
title = {{Streaming trend detection in Twitter}},
url = {http://www.inderscience.com/link.php?id=51298},
volume = {9},
year = {2013}
}
@article{Roberts2013,
abstract = {Collection and especially analysis of open-ended survey responses are relatively rare in the discipline and when conducted are almost exclusively done through human coding. We present an alternative, semiautomated approach, the structural topic model (STM) (Roberts, Stewart, andAiroldi 2013; Roberts et al. 2013), that draws on recent developments in machine learning based analysis of textual data. A crucial contribution of the method is that it incorporates information about the document, such as the author's gender, political affiliation, and treatment assignment (if an experimental study). This article focuses on how the STMis helpful for survey researchers and experimentalists. The STM makes analyzing open-ended responses easier, more revealing, and capable of being used to estimate treatment effects. We illustrate these innovations with analysis of text from surveys and experiments.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Roberts, Margaret E and Stewart, Brandon M and Tingley, Dustin and Lucas, Christopher and Leder-Luis, Jetson and Gadarian, Shana Kushner and Albertson, Bethany and Rand, David G},
doi = {10.1111/ajps.12103},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/topicmodelsopenendedexperiments.pdf:pdf},
isbn = {0092-5853},
issn = {15405907},
journal = {American Journal of Political Science},
number = {4},
pages = {1064--1082},
pmid = {25246403},
title = {{Structural topic models for open-ended survey responses}},
volume = {58},
year = {2014}
}
@article{Landauer,
author = {Landauer, Thomas K and Dutnais, Susan T},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/271ee62d1d45311b21f2bf7aff2ba97e7d8f.pdf:pdf},
number = {2},
pages = {211--240},
title = {{A Solution to Plato ' s Problem : The Latent Semantic Analysis Theory of Acquisition , Induction , and Representation of Knowledge}},
volume = {1},
year = {1997}
}
@article{Rosen-Zvi2012,
abstract = {We introduce the author-topic model, a generative model for documents that extends Latent Dirichlet Allocation (LDA; Blei, Ng, {\&} Jordan, 2003) to include authorship information. Each author is associated with a multinomial distribution over topics and each topic is associated with a multinomial distribution over words. A document with multiple authors is modeled as a distribution over topics that is a mixture of the distributions associated with the authors. We apply the model to a collection of 1,700 NIPS conference papers and 160,000 CiteSeer abstracts. Exact inference is intractable for these datasets and we use Gibbs sampling to estimate the topic and author distributions. We compare the performance with two other generative models for documents, which are special cases of the author-topic model: LDA (a topic model) and a simple author model in which each author is associated with a distribution over words rather than a distribution over topics. We show topics recovered by the author-topic model, and demonstrate applications to computing similarity between authors and entropy of author output.},
archivePrefix = {arXiv},
arxivId = {1207.4169},
author = {Rosen-Zvi, Michal and Griffiths, Thomas and Steyvers, Mark and Smyth, Padhraic},
eprint = {1207.4169},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/The{\_}Author-Topic{\_}Model{\_}for{\_}Authors{\_}and{\_}Documents.pdf:pdf},
number = {January},
title = {{The Author-Topic Model for Authors and Documents}},
url = {http://arxiv.org/abs/1207.4169},
year = {2012}
}
@article{Grimmer2013,
abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Grimmer, Justin and Stewart, Brandon M.},
doi = {10.1093/pan/mps028},
eprint = {9605103},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/tad2.pdf:pdf},
isbn = {1047-1987},
issn = {14764989},
journal = {Political Analysis},
number = {3},
pages = {267--297},
primaryClass = {cs},
title = {{Text as data: The promise and pitfalls of automatic content analysis methods for political texts}},
volume = {21},
year = {2013}
}
@article{Krishnamurthy2008,
abstract = {Web 2.0 has brought about several new applications that have en- abled arbitrary subsets of users to communicate with each other on a social basis. Such communication increasingly happens not just on Facebook and MySpace but on several smaller network applica- tions such as Twitter and Dodgeball. We present a detailed charac- terization of Twitter, an application that allows users to send short messages. We gathered three datasets (covering nearly 100,000 users) including constrained crawls of the Twitter network using two different methodologies, and a sampled collection from the publicly available timeline. We identify distinct classes of Twitter users and their behaviors, geographic growth patterns and current size of the network, and compare crawl results obtained under rate limiting constraints.},
author = {Krishnamurthy, Balachander and Gill, Phillipa and Arlitt, Martin},
doi = {10.1145/1397735.1397741},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/A Few Chirps About Twitter.pdf:pdf},
isbn = {9781605581828},
journal = {Proceedings of the first workshop on Online social networks - WOSP '08},
keywords = {measurement,online social networks},
pages = {19},
title = {{A few chirps about twitter}},
url = {http://portal.acm.org/citation.cfm?doid=1397735.1397741},
year = {2008}
}
@article{Blei2012,
author = {Blei, David M},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/p77-blei.pdf:pdf},
pages = {77--84},
title = {{Probabilistic Topic Models}},
year = {2012}
}
@article{Yldrm2016,
abstract = {Twitter is an extremely high volume platform for user generated contributions regarding any topic. The wealth of content created at real-time in massive quantities calls for automated approaches to identify the topics of the contributions. Such topics can be utilized in numerous ways, such as public opinion mining, marketing, entertainment, and disaster management. Towards this end, approaches to relate single or partial posts to knowledge base items have been proposed. However, in microblogging systems like Twitter, topics emerge from the culmination of a large number of contributions. Therefore, identifying topics based on collections of posts, where individual posts contribute to some aspect of the greater topic is necessary. Models, such as Latent Dirichlet Allocation (LDA), propose algorithms for relating collections of posts to sets of keywords that represent underlying topics. In these approaches, figuring out what the specific topic(s) the keyword sets represent remains as a separate task. Another issue in topic detection is the scope, which is often limited to specific domain, such as health. This work proposes an approach for identifying domain-independent specific topics related to sets of posts. In this approach, individual posts are processed and then aggregated to identify key tokens, which are then mapped to specific topics. Wikipedia article titles are selected to represent topics, since they are up to date, user-generated, sophisticated articles that span topics of human interest. This paper describes the proposed approach, a prototype implementation, and a case study based on data gathered during the heavily contributed periods corresponding to the four US election debates in 2012. The manually evaluated results (0.96 precision) and other observations from the study are discussed in detail.},
author = {Yıldırım, Ahmet and {\"{U}}sk{\"{u}}darli, Suzan and {\"{O}}zg{\"{u}}r, Arzucan},
doi = {10.1371/journal.pone.0151885},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Identifying Topics in Microblogs Using.pdf:pdf},
isbn = {1932-6203},
issn = {19326203},
journal = {PLoS ONE},
number = {3},
pages = {1--20},
pmid = {26991442},
title = {{Identifying topics in microblogs using wikipedia}},
volume = {11},
year = {2016}
}
@article{Blei2007,
author = {Blei, David and John, Lafferty},
doi = {10.1214/07-AOAS114},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/26ecd664041da611d60393443dc2680dc0e3.pdf:pdf},
number = {1},
pages = {17--35},
title = {{A correlated topic model of}},
volume = {1},
year = {2007}
}
@article{Mazarura2014,
abstract = {See, stats, and : https : / / www . researchgate . net / publication / 279195527 Topic Conference CITATIONS 2 READS 256 4 , including : Some : Transdisciplinary Text Jocelyn University 2 SEE Alta University 37 SEE Sollie University 13 SEE All . The . Abstract—The purpose of this work is to understand the performance of probabilistic topic models on short text such as microblogs and tweets . We compared two topic models - the Multinomial Mixture (MM) and Latent Dirichlet Allocation (LDA) - using perplexity as the performance measure . The MM model assumes that a document is associated with one topic , whereas LDA assumes that a document is a mixture of topics . Our initial results indicate that MM performs better on a short text corpus (tweets) than LDA .},
author = {Mazarura, Jocelyn and Waal, Alta De and Kanfer, Frans and Millard, Sollie},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Topic Modelling For Short Text.pdf:pdf},
journal = {Prasa.Org},
keywords = {LDA,Multinomial Mixture},
mendeley-tags = {LDA,Multinomial Mixture},
title = {{Topic Modelling for Short Text}},
url = {http://www.prasa.org/proceedings/2014/prasa2014-03.pdf},
year = {2014}
}
@article{Hong2010,
abstract = {Social networks such as Facebook, LinkedIn, and Twitter have been a crucial source of information for a wide spectrum of users. In Twitter, popular information that is deemed important by the community propagates through the network. Studying the characteristics of content in the messages becomes important for a number of tasks, such as breaking news detection, personalized message recommendation, friends recommendation, sentiment analysis and others. While many researchers wish to use standard text mining tools to understand messages on Twitter, the restricted length of those messages prevents them from being employed to their full potential. We address the problem of using standard topic models in microblogging environments by studying how the models can be trained on the dataset. We propose several schemes to train a standard topic model and compare their quality and effectiveness through a set of carefully designed experiments from both qualitative and quantitative perspectives. We show that by training a topic model on aggregated messages we can obtain a higher quality of learned model which results in significantly better performance in two real- world classification problems. We also discuss how the state-of- the-artAuthor-Topicmodel fails to model hierarchical relationships between entities in SocialMedia.},
author = {Hong, Liangjie and Davison, Brian D.},
doi = {10.1145/1964858.1964870},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Empirical Study of Topic Modeling in Twitter.pdf:pdf},
isbn = {9781450302173},
issn = {15278999},
journal = {- SOMA '10},
keywords = {social media,topic models,twitter},
pages = {80--88},
pmid = {282},
title = {{Empirical study of topic modeling in Twitter}},
url = {http://portal.acm.org/citation.cfm?doid=1964858.1964870},
year = {2010}
}
@article{Blei2006,
author = {Blei, David M and Lafferty, John D},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/dynamic{\_}topic{\_}models.pdf:pdf},
title = {{Dynamic Topic Models}},
year = {2006}
}
@article{Mazarura2014a,
abstract = {See, stats, and : https : / / www . researchgate . net / publication / 279195527 Topic Conference CITATIONS 2 READS 256 4 , including : Some : Transdisciplinary Text Jocelyn University 2 SEE Alta University 37 SEE Sollie University 13 SEE All . The . Abstract—The purpose of this work is to understand the performance of probabilistic topic models on short text such as microblogs and tweets . We compared two topic models - the Multinomial Mixture (MM) and Latent Dirichlet Allocation (LDA) - using perplexity as the performance measure . The MM model assumes that a document is associated with one topic , whereas LDA assumes that a document is a mixture of topics . Our initial results indicate that MM performs better on a short text corpus (tweets) than LDA .},
author = {Mazarura, Jocelyn and Waal, Alta De and Kanfer, Frans and Millard, Sollie},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Topic Modelling For Short Text.pdf:pdf},
journal = {Prasa.Org},
keywords = {LDA,MM},
mendeley-tags = {LDA,MM},
title = {{Topic Modelling for Short Text}},
url = {http://www.prasa.org/proceedings/2014/prasa2014-03.pdf},
year = {2014}
}
@article{Cheng2015,
abstract = {Topic models have achieved significant successes in analyzing large-scale text corpus. In practical applications, we are always confronted with the challenge of model selection, i.e., how to appropriately set the number of topics. Following the recent advances in topic models via tensor decomposition, we make a first attempt to provide theoretical analysis on model selection in latent Dirichlet allocation. With mild conditions, we derive the upper bound and lower bound on the number of topics given a text collection of finite size. Experimental results demonstrate that our bounds are correct and tight. Furthermore, using Gaussian mixture model as an example, we show that our methodology can be easily generalized to model selection analysis in other latent models.},
author = {Cheng, Dehua and He, Xinran and Liu, Yan},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Model Selection for Topic Models via Spectral Decomposition.pdf:pdf},
journal = {18th International Conference on Artificial Intelligence and Statistics},
keywords = {topic evaluation,topic modelling,twitter},
mendeley-tags = {topic evaluation,topic modelling,twitter},
pages = {183--191},
title = {{Model Selection for Topic Models via Spectral Decomposition}},
volume = {38},
year = {2015}
}
@article{Jelodar2017,
abstract = {Topic modeling is one of the most powerful techniques in text mining for data mining, latent data discovery, and finding relationships among data, text documents. Researchers have published many articles in the field of topic modeling and applied in various fields such as software engineering, political science, medical and linguistic science, etc. There are various methods for topic modeling, which Latent Dirichlet allocation (LDA) is one of the most popular methods in this field. Researchers have proposed various models based on the LDA in topic modeling. According to previous work, this paper can be very useful and valuable for introducing LDA approaches in topic modeling. In this paper, we investigated scholarly articles highly (between 2003 to 2016) related to Topic Modeling based on LDA to discover the research development, current trends and intellectual structure of topic modeling. Also, we summarize challenges and introduce famous tools and datasets in topic modeling based on LDA.},
archivePrefix = {arXiv},
arxivId = {1711.04305v1},
author = {Jelodar, Hamed and Wang, Yongli and Yuan, Chi and Feng, Xia},
doi = {10.16288/j.yczz.17-199},
eprint = {1711.04305v1},
file = {:C$\backslash$:/Users/amwangi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jelodar et al. - 2017 - Latent Dirichlet Allocation (LDA) and Topic modeling models, applications, a survey.pdf:pdf},
isbn = {0000000345},
issn = {0960-8524},
journal = {arXiv:1711.04305v1 [cs.IR]},
keywords = {EM,Gibbs sampling,LDA,Latent Dirichlet Allocation,VB Inference,expectation maximization,topic modelling},
mendeley-tags = {EM,LDA,VB Inference},
pages = {1--13},
title = {{Latent Dirichlet Allocation (LDA) and Topic modeling: models, applications, a survey}},
url = {https://arxiv.org/abs/1711.04305v1},
year = {2017}
}
@article{Jacobi2016,
abstract = {The huge collections of news content which have become available through digital technologies both enable and warrant scientific inquiry, challenging journalism scholars to analyse unprecedented amounts of texts. We propose Latent Dirichlet Allocation (LDA) topic modelling as a tool to face this challenge. LDA is a cutting edge technique for content analysis, designed to automatically organize large archives of documents based on latent topics, measured as patterns of word (co-)occurrence. We explain how this technique works, how different choices by the researcher affect the results and how the results can be meaningfully interpreted. To demonstrate its usefulness for journalism research, we conducted a case study of the New York Times coverage of nuclear technology from 1945 to the present, partially replicating a study by Gamson and Modigliani. This shows that LDA is a useful tool for analysing trends and patterns in news content in large digital news archives relatively quickly.},
author = {Jacobi, Carina and {Van Atteveldt}, Wouter and Welbers, Kasper},
doi = {10.1080/21670811.2015.1093271},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Quantitative analysis of large amounts of journalistic texts using topic.pdf:pdf},
isbn = {2167-0811},
issn = {2167082X},
journal = {Digital Journalism},
keywords = {Automatic content analysis,Journalism,Nuclear energy,Topic models},
number = {1},
pages = {89--106},
pmid = {21698847},
title = {{Quantitative analysis of large amounts of journalistic texts using topic modelling}},
volume = {4},
year = {2016}
}
@article{Wesslen2018,
abstract = {Topic models are a family of statistical-based algorithms to summarize, explore and index large collections of text documents. After a decade of research led by computer scientists, topic models have spread to social science as a new generation of data-driven social scientists have searched for tools to explore large collections of unstructured text. Recently, social scientists have contributed to topic model literature with developments in causal inference and tools for handling the problem of multi-modality. In this paper, I provide a literature review on the evolution of topic modeling including extensions for document covariates, methods for evaluation and interpretation, and advances in interactive visualizations along with each aspect's relevance and application for social science research.},
archivePrefix = {arXiv},
arxivId = {1803.11045},
author = {Wesslen, Ryan},
eprint = {1803.11045},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Computer-Assisted Text Analysis for Social Science - Topic Models and beyond.pdf:pdf},
keywords = {Lit Review,analysis,computational social science,computer-assisted text,structural topic model,visual analytics},
mendeley-tags = {Lit Review},
title = {{Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond}},
url = {http://arxiv.org/abs/1803.11045},
year = {2018}
}
@article{Ramage2010,
abstract = {As microblogging grows in popularity, services like Twitter are coming to support information gathering needs above and beyond their traditional roles as social networks. But most users' focused on interaction with Twitter their representations of content is for solving still primarily social graphs, forcing the often inappropriate conflation of “people I follow” with “stuff I want to read.” We characterize some information needs that the current Twitter interface fails to support, and argue for better these challenges. We present a scalable implementation of a partially supervised learning model (Labeled LDA) that maps the content of the Twitter feed into dimensions. These dimensions correspond roughly to substance, style, status, and social characteristics of posts. We characterize users and tweets using this model, and present results on two information consumption oriented tasks.},
author = {Ramage, Daniel and Dumais, Susan and Liebling, Dan},
doi = {10.1.1.309.2194},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Characterizing Microblogs with Topic Models.pdf:pdf},
isbn = {9781577354451},
journal = {Icwsm},
pages = {1--8},
title = {{Characterizing Microblogs with Topic Models}},
year = {2010}
}
@article{Deerwester,
author = {Deerwester, Scott and Furnas, George W and Landauer, Thomas K and Harshman, Richard},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Latent Semantic Analyis.pdf:pdf},
title = {{Indexing by Latent Semantic Analysis}},
year = {1990}
}
@article{Bhattacharya2014,
abstract = {We propose a novel mechanism to infer topics of interest of individual users in the Twitter social network. We observe that in Twitter, a user generally follows experts on various topics of her interest in order to acquire information on those topics. We use a methodology based on social annotations (proposed earlier by us) to first deduce the topical expertise of popular Twitter users, and then transitively infer the interests of the users who follow them. This methodology is a sharp departure from the traditional techniques of inferring interests of a user from the tweets that she posts or receives. We show that the topics of interest inferred by the proposed methodology are far superior than the topics extracted by state-of-the-art techniques such as using topic models (Labeled LDA) on tweets. Based upon the proposed methodology, we build a system Who Likes What, which can infer the interests of millions of Twitter users. To our knowledge, this is the first system that can infer interests for Twitter users at such scale. Hence, this system would be particularly beneficial in developing personalized recommender services over the Twitter platform.},
archivePrefix = {arXiv},
arxivId = {1010.3003},
author = {Bhattacharya, Parantapa and Ganguly, Niloy and Ghosh, Saptarshi and Zafar, Muhammad Bilal and Gummadi, Krishna P.},
doi = {10.1145/2645710.2645765},
eprint = {1010.3003},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/p357-bhattacharya.pdf:pdf},
isbn = {9781450326681},
issn = {18777503},
keywords = {labeled lda,lists,twitter,user interests},
pages = {357--360},
pmid = {22173204},
title = {{Inferring user interests in the Twitter social network}},
year = {2014}
}
@article{Blei,
author = {Blei, David M and Lafferty, John D},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/BleiLafferty2009.pdf:pdf},
title = {{Topic models}},
year = {2009}
}
@article{Hajjem2017,
abstract = {Twitter is a networking micro-blogging service where users post millions of short messages every day. Building multilingual corpora from these microblogs contents can be useful to perform several computational tasks such as opinion mining. However, Twitter data gathering involves the problem of irrelevant included data. Recent literary works have proved that topic models such as Latent Dirichlet Allocation (LDA) are not consistent when applied to short texts like tweets. In order to prune the irrelevant tweets, we investigate in this paper a novel method to improve topics learned from Twitter content without modifying the basic machinery of LDA. This latter is based on a pooling process which combines Information retrieval (IR) approach and LDA.This is achieved through an aggregation strategy based on IR task to retrieve similar tweets in a same cluster. The result of tweet pooling is then used as an input for a basic LDA to overcome the sparsity problem of Twitter content. Empirical results highlight that tweets aggregation based on IR and LDA leads to an interesting improvement in a variety of measures for topic coherence, in comparison to unmodified LDA baseline and a variety of pooling schemes.},
author = {Hajjem, Malek and Latiri, Chiraz},
doi = {10.1016/j.procs.2017.08.166},
file = {:C$\backslash$:/Users/amwangi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hajjem, Latiri - 2017 - Combining IR and LDA Topic Modeling for Filtering Microblogs.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Aggregation,Information Retrieval,LDA,Microblogs,Pruning irrelevant tweets},
pages = {761--770},
publisher = {Elsevier B.V.},
title = {{Combining IR and LDA Topic Modeling for Filtering Microblogs}},
url = {http://dx.doi.org/10.1016/j.procs.2017.08.166},
volume = {112},
year = {2017}
}
@article{Arabshahi2016,
abstract = {In this paper, we propose guaranteed spectral methods for learning a broad range of topic models, which generalize the popular Latent Dirichlet Allocation (LDA). We overcome the limitation of LDA to incorporate arbitrary topic correlations, by assuming that the hidden topic proportions are drawn from a flexible class of Normalized Infinitely Divisible (NID) distributions. NID distributions are generated through the process of normalizing a family of independent Infinitely Divisible (ID) random variables. The Dirichlet distribution is a special case obtained by normalizing a set of Gamma random variables. We prove that this flexible topic model class can be learned via spectral methods using only moments up to the third order, with (low order) polynomial sample and computational complexity. The proof is based on a key new technique derived here that allows us to diagonalize the moments of the NID distribution through an efficient procedure that requires evaluating only univariate integrals, despite the fact that we are handling high dimensional multivariate moments. In order to assess the performance of our proposed Latent NID topic model, we use two real datasets of articles collected from New York Times and Pubmed. Our experiments yield improved perplexity on both datasets compared with the baseline.},
archivePrefix = {arXiv},
arxivId = {1605.09080},
author = {Arabshahi, Forough and Anandkumar, Animashree},
eprint = {1605.09080},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Spectral Methods for Correlated Topic Models.pdf:pdf},
keywords = {LDA,NID,finitely divisible,in-,latent variable models,l{\'{e}}vy processes,moment matching,ods,spectral,spectral meth-,tensor decomposition},
mendeley-tags = {LDA,NID,spectral},
title = {{Spectral Methods for Correlated Topic Models}},
url = {http://arxiv.org/abs/1605.09080},
volume = {54},
year = {2016}
}
@article{Blei2003a,
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
doi = {http://dx.doi.org/10.1162/jmlr.2003.3.4-5.993},
eprint = {1111.6189v1},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/nips01-lda Latent Dirchlet.pdf:pdf},
isbn = {9781577352815},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
keywords = {LDA,generative model},
mendeley-tags = {LDA,generative model},
number = {3},
pages = {993--1022},
pmid = {21362469},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}
@article{Hofmann2001,
author = {Hofmann, Thomas},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Hofmann2001{\_}Article{\_}UnsupervisedLearningByProbabil.pdf:pdf},
keywords = {dimension reduction,em algorithm,information retrieval,language modeling,latent class models,mixture models,natural language processing,unsupervised learning},
pages = {177--196},
title = {{Unsupervised Learning by Probabilistic Latent Semantic Analysis}},
year = {2001}
}
@article{Lau2012,
abstract = {We present a novel topic modelling-based methodology to track emerging events in microblogs such as Twitter. Our topic model has an in-built update mechanism based on time slices and implements a dynamic vocabulary. We first show that the method is robust in detecting events using a range of datasets with injected novel events, and then demonstrate its application in identifying trending topics in Twitter.},
author = {Lau, JeyHan and Collier, Nigel and Baldwin, Timothy},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/On-line Trend Analysis with Topic Models.pdf:pdf},
journal = {International Conference on Computational Linguistics (COLING)},
keywords = {Background,Introduction,Online Processing.,Problem Statement,Topic Evolution,Topic Model,Trend Detection},
mendeley-tags = {Background,Introduction},
number = {December},
pages = {1519--1534},
title = {{On-line Trend Analysis with Topic Models: {\#}twitter Trends Detection Topic Model Online}},
url = {https://www.aclweb.org/anthology/C/C12/C12-1093.pdf},
volume = {2},
year = {2012}
}
@article{Java2007,
abstract = {Microblogging is a new form of communication in which users can describe their current status in short posts dis- tributed by instant messages, mobile phones, email or the Web. Twitter, a popular microblogging tool has seen a lot of growth since it launched in October, 2006. In this paper, we present our observations of the microblogging phenom- ena by studying the topological and geographical properties of Twitter's social network. We find that people use mi- croblogging to talk about their daily activities and to seek or share information. Finally, we analyze the user intentions associated at a community level and show how users with similar intentions connect with each other. Categories},
archivePrefix = {arXiv},
arxivId = {1008.1253},
author = {Java, Akshay and Song, Xiaodan and Finin, Tim and Tseng, Belle},
doi = {10.1145/1348549.1348556},
eprint = {1008.1253},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Why We Twitter Understanding Microblogging.pdf:pdf},
isbn = {9781595938480},
issn = {00016993},
journal = {Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis - WebKDD/SNA-KDD '07},
keywords = {Computer Applications,Information Search and Retrieval},
pages = {56--65},
pmid = {1418271},
title = {{Why We Twitter: Understanding Microblogging Usage and Communities}},
url = {http://portal.acm.org/citation.cfm?doid=1348549.1348556},
year = {2007}
}
@article{Zimbra2017,
author = {Zimbra, David and Abbasi, Ahmed and Zeng, D and Chen, H},
doi = {10.1145/0000000.0000000},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/State of the art Twitter Sentiment Analysis.pdf:pdf},
journal = {Acm Tmis},
keywords = {Introduction,research questions},
mendeley-tags = {Introduction,research questions},
number = {March},
title = {{The State-of-the-Art in Twitter Sentiment Analysis: A Review and Benchmark Evaluation}},
volume = {Forthcomin},
year = {2017}
}
@article{Griffiths2004,
author = {Griffiths, Thomas L and Steyvers, Mark},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/ef997ae1b01762b57b75d8c22fb8cec87406.pdf:pdf},
title = {{Finding scientific topics}},
year = {2004}
}
@article{Zhao2011,
abstract = {Twitter as a new form of social media can potentially con- tain much useful information, but content analysis on Twitter has not been well studied. In particular, it is not clear whether as an information source Twitter can be simply regarded as a faster news feed that covers mostly the same information as traditional news media. In This paper we empirically compare the content of Twitter with a traditional news medium, New York Times, using unsupervised topic modeling. We use a Twitter-LDA model to discover topics from a representative sample of the entire Twitter.We then use text mining techniques to compare these Twitter topics with topics from New York Times, taking into considera- tion topic categories and types. We also study the relation between the proportions of opinionated tweets and retweets and topic categories and types. Our comparisons show interesting and useful findings for down- stream IR or DM applications.},
author = {Zhao, Wayne Xin and Jiang, Jing and Weng, Jianshu and He, Jing and Lim, Ee-peng and Yan, Hongfei and Li, Xiaoming},
doi = {10.1007/978-3-642-20161-5_34},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/2011-ECIR-Comparing Twitter and Traditional Media Using Topic Models .pdf:pdf},
isbn = {978-3-642-20160-8},
journal = {Proceedings of the 33rd European conference on Advances in information retrieval (ECIR'11)},
keywords = {Questions,microblogging,topic modeling,twitter},
mendeley-tags = {Questions},
pages = {338--349},
title = {{Comparing Twitter and Traditional Media using Topic Models}},
year = {2011}
}
@article{Xu2011a,
abstract = {Microblogging has become a primary channel by which people not only share information, but also search for information. However, microblog search results are most often displayed by simple criteria such as creation time or author. A review of the literature suggests that clustering by topic may be useful, but short posts offer limited scope for clustering using lexical evidence alone. This paper therefore presents an approach to topical clustering based on augmenting lexical evidence with the use of Wikipedia as an external source of evidence for topical similarity. The main idea is to link terms in microblog posts to Wikipedia pages and then to leverage Wikipedia's link structure to estimate semantic similarity, Results show statistically significant relative improvements of about 3{\%} in cluster purity using a relatively small (7500-post, 5-topic) Twitter test collection. Linking terms in microblog posts to Wikipedia pages is also shown to offer a useful basis for cluster labeling.},
author = {Xu, Tan and Oard, Douglas W.},
doi = {10.1002/meet.2011.14504801186},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Wikipedia-based Topic Clustering for Microblogs.pdf:pdf},
isbn = {1550-8390},
issn = {15508390},
journal = {Proceedings of the ASIST Annual Meeting},
keywords = {Cluster labeling,Microblog search,Topic clustering,Topic detection,Wikipedia},
title = {{Wikipedia-based topic clustering for microblogs}},
volume = {48},
year = {2011}
}
@article{Blei2003,
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Blei, David M and Edu, Blei@cs Berkeley and Ng, Andrew Y and Edu, Ang@cs Stanford and Jordan, Michael I and Edu, Jordan@cs Berkeley},
doi = {10.1162/jmlr.2003.3.4-5.993},
eprint = {1111.6189v1},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Latent Dirichlet Allocation.pdf:pdf},
isbn = {9781577352815},
issn = {15324435},
journal = {Journal of Machine Learning Research},
pages = {993--1022},
pmid = {21362469},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}
@article{Yldrm2018,
abstract = {The extensive use of social media for sharing and obtaining information has resulted in the development of topic detection models to facilitate the comprehension of the overwhelming amount of short and distributed posts. Probabilistic topic models, such as Latent Dirichlet allocation, represent topics as sets of terms that are useful for many automated processes. However, the determination of what a topic is about is left as a further task. Alternatively, techniques that produce summaries are human comprehensible, but less suitable for automated processing. This work proposes an approach that utilizes Linked Open Data (LOD) resources to extract semantically represented topics from collections of microposts. The proposed approach utilizes entity linking to identify the elements of topics from microposts. The elements are related through co-occurrence graphs, which are processed to yield topics. The topics are represented using an ontology that is introduced for this purpose. A prototype of the approach is used to identify topics from 11 datasets consisting of more than one million posts collected from Twitter during various events, such as the 2016 US election debates and the death of Carrie Fisher. The characteristics of the approach and more than 5 thousand generated topics are described in detail. A human evaluation of topics from 30 randomly selected intervals resulted in a precision of 81.0{\%} and F1 score of 93.3{\%}. Furthermore, they are compared with topics generated from the same datasets with two different kinds of topic models. The potentials of semantic topics in revealing information, that is not otherwise easily observable, is demonstrated with semantic queries of various complexities.},
archivePrefix = {arXiv},
arxivId = {1804.02158},
author = {Yıldırım, Ahmet and Uskudarli, Suzan},
eprint = {1804.02158},
file = {:D$\backslash$:/MSc DA/Project docs/Research Papers/Identifying Topics from Micropost Collections.pdf:pdf},
pages = {1--56},
title = {{Identifying Topics from Micropost Collections using Linked Open Data}},
url = {http://arxiv.org/abs/1804.02158},
year = {2018}
}
